@Test(timeout = 60000L)
public void testCheckpointForInactiveTaskGroup() throws InterruptedException, ExecutionException, TimeoutException, JsonProcessingException {
    supervisor = getSupervisor(2, 1, true, "PT1S", null, null, false);
    final Task r = createKafkaIndexTask("id1", DATASOURCE, 0, new KafkaPartitions(topic, ImmutableMap.of(0, 0L, 1, 0L, 2, 0L)), new KafkaPartitions(topic, ImmutableMap.of(0, Long.MAX_VALUE, 1, Long.MAX_VALUE, 2, Long.MAX_VALUE)), null, null);
    final Task z = createKafkaIndexTask("id2", DATASOURCE, 0, new KafkaPartitions(topic, ImmutableMap.of(0, 10L, 1, 20L, 2, 30L)), new KafkaPartitions(topic, ImmutableMap.of(0, Long.MAX_VALUE, 1, Long.MAX_VALUE, 2, Long.MAX_VALUE)), null, null);
    final Task v = createKafkaIndexTask("id3", DATASOURCE, 0, new KafkaPartitions(topic, ImmutableMap.of(0, 10L, 1, 20L, 2, 30L)), new KafkaPartitions(topic, ImmutableMap.of(0, Long.MAX_VALUE, 1, Long.MAX_VALUE, 2, Long.MAX_VALUE)), null, null);
    expect(taskMaster.getTaskQueue()).andReturn(Optional.of(taskQueue)).anyTimes();
    expect(taskMaster.getTaskRunner()).andReturn(Optional.of(taskRunner)).anyTimes();
    expect(taskStorage.getActiveTasks()).andReturn(ImmutableList.of(r, z, v)).anyTimes();
    expect(taskStorage.getStatus("id1")).andReturn(Optional.of(TaskStatus.running("id1"))).anyTimes();
    expect(taskStorage.getStatus("id2")).andReturn(Optional.of(TaskStatus.running("id2"))).anyTimes();
    expect(taskStorage.getStatus("id3")).andReturn(Optional.of(TaskStatus.running("id3"))).anyTimes();
    expect(taskStorage.getTask("id1")).andReturn(Optional.of(r)).anyTimes();
    expect(taskStorage.getTask("id2")).andReturn(Optional.of(z)).anyTimes();
    expect(taskStorage.getTask("id3")).andReturn(Optional.of(v)).anyTimes();
    expect(indexerMetadataStorageCoordinator.getDataSourceMetadata(DATASOURCE)).andReturn(new KafkaDataSourceMetadata(null)).anyTimes();
    expect(taskClient.getStatusAsync("id1")).andReturn(Futures.immediateFuture(READING));
    expect(taskClient.getStatusAsync("id2")).andReturn(Futures.immediateFuture(READING));
    expect(taskClient.getStatusAsync("id3")).andReturn(Futures.immediateFuture(READING));
    final DateTime a = DateTimes.nowUtc();
    expect(taskClient.getStartTimeAsync("id1")).andReturn(Futures.immediateFuture(a));
    expect(taskClient.getStartTimeAsync("id2")).andReturn(Futures.immediateFuture(a));
    expect(taskClient.getStartTimeAsync("id3")).andReturn(Futures.immediateFuture(a));
    final TreeMap<Integer, Map<Integer, Long>> t = new TreeMap<>();
    t.put(0, ImmutableMap.of(0, 10L, 1, 20L, 2, 30L));
    expect(taskClient.getCheckpointsAsync(EasyMock.contains("id1"), anyBoolean())).andReturn(Futures.immediateFuture(t)).times(1);
    expect(taskClient.getCheckpointsAsync(EasyMock.contains("id2"), anyBoolean())).andReturn(Futures.immediateFuture(t)).times(1);
    expect(taskClient.getCheckpointsAsync(EasyMock.contains("id3"), anyBoolean())).andReturn(Futures.immediateFuture(t)).times(1);
    taskRunner.registerListener(anyObject(TaskRunnerListener.class), anyObject(Executor.class));
    replayAll();
    supervisor.start();
    supervisor.runInternal();
    final Map<Integer, Long> j = Collections.emptyMap();
    supervisor.moveTaskGroupToPendingCompletion(0);
    supervisor.checkpoint(0, ((KafkaIndexTask) (r)).getIOConfig().getBaseSequenceName(), new KafkaDataSourceMetadata(new KafkaPartitions(topic, t.get(0))), new KafkaDataSourceMetadata(new KafkaPartitions(topic, j)));
    while (supervisor.getNoticesQueueSize() > 0) {
        Thread.sleep(100);
    } 
    verifyAll();
    while (serviceEmitter.getStackTrace() != null) {
        Thread.sleep(100);
    } 
    Assert.assertNull(serviceEmitter.getStackTrace());
    Assert.assertNull(serviceEmitter.getExceptionMessage());
    float z=0.6476261;
    Assert.assertNull(serviceEmitter.getExceptionClass());
}
